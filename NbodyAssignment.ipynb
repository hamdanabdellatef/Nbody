{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamdanabdellatef/Nbody/blob/main/NbodyAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run this first to get the codes and setup the enviroment"
      ],
      "metadata": {
        "id": "R3apYEbTsq8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb\n",
        "!apt update\n",
        "!apt install ./nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb\n",
        "!apt --fix-broken install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiLY3LbhwuVk",
        "outputId": "fbca1758-a573-46e7-97be-b8519d48612b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-15 21:42:43--  https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.199.39.144\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.199.39.144|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 317705436 (303M) [application/x-deb]\n",
            "Saving to: ‘nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb’\n",
            "\n",
            "nsight-systems-2023 100%[===================>] 302.99M   344MB/s    in 0.9s    \n",
            "\n",
            "2024-11-15 21:42:44 (344 MB/s) - ‘nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb’ saved [317705436/317705436]\n",
            "\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,108 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,164 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,616 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,701 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,425 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,453 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,482 kB]\n",
            "Fetched 20.3 MB in 5s (4,490 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "55 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'nsight-systems-2023.2.3' instead of './nsight-systems-2023.2.3_2023.2.3.1001-1_amd64.deb'\n",
            "The following additional packages will be installed:\n",
            "  libtinfo5 libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n",
            "  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxkbcommon-x11-0 libxtst6\n",
            "The following NEW packages will be installed:\n",
            "  libtinfo5 libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n",
            "  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxkbcommon-x11-0 libxtst6 nsight-systems-2023.2.3\n",
            "0 upgraded, 12 newly installed, 0 to remove and 55 not upgraded.\n",
            "Need to get 318 MB of archives.\n",
            "After this operation, 1,269 kB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  nsight-systems-2023.2.3 2023.2.3.1001-32894139v0 [318 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libtinfo5 amd64 6.3-2ubuntu0.1 [100 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n",
            "Fetched 318 MB in 3s (96.0 MB/s)\n",
            "Selecting previously unselected package libtinfo5:amd64.\n",
            "(Reading database ... 123629 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libtinfo5_6.3-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtinfo5:amd64 (6.3-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libxcb-xinerama0:amd64.\n",
            "Preparing to unpack .../01-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xinput0:amd64.\n",
            "Preparing to unpack .../02-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xkb1:amd64.\n",
            "Preparing to unpack .../03-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxkbcommon-x11-0:amd64.\n",
            "Preparing to unpack .../04-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n",
            "Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../05-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libxcb-icccm4:amd64.\n",
            "Preparing to unpack .../06-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n",
            "Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Selecting previously unselected package libxcb-util1:amd64.\n",
            "Preparing to unpack .../07-libxcb-util1_0.4.0-1build2_amd64.deb ...\n",
            "Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Selecting previously unselected package libxcb-image0:amd64.\n",
            "Preparing to unpack .../08-libxcb-image0_0.4.0-2_amd64.deb ...\n",
            "Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Selecting previously unselected package libxcb-keysyms1:amd64.\n",
            "Preparing to unpack .../09-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n",
            "Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Selecting previously unselected package libxcb-render-util0:amd64.\n",
            "Preparing to unpack .../10-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n",
            "Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Selecting previously unselected package nsight-systems-2023.2.3.\n",
            "Preparing to unpack .../11-nsight-systems-2023.2.3_2023.2.3.1001-32894139v0_amd64.deb ...\n",
            "Unpacking nsight-systems-2023.2.3 (2023.2.3.1001-32894139v0) ...\n",
            "Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Setting up libtinfo5:amd64 (6.3-2ubuntu0.1) ...\n",
            "Setting up nsight-systems-2023.2.3 (2023.2.3.1001-32894139v0) ...\n",
            "update-alternatives: using /opt/nvidia/nsight-systems/2023.2.3/target-linux-x64/nsys to provide /usr/local/bin/nsys (nsys) in auto mode\n",
            "update-alternatives: using /opt/nvidia/nsight-systems/2023.2.3/host-linux-x64/nsys-ui to provide /usr/local/bin/nsys-ui (nsys-ui) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 56 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hamdanabdellatef/Nbody.git\n",
        "%cd Nbody"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWGdNE50sqMD",
        "outputId": "1b483cdc-17b9-4a52-a001-668e95a2db88"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Nbody'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 5 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (5/5), done.\n",
            "/content/Nbody\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Here is an example\n",
        "\n",
        "How to compile and run cuda c in colab, and profile it with nsys"
      ],
      "metadata": {
        "id": "UYW2yGN5vAL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -std=c++11 -o vectoradd 01-vector-add.cu -run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LppB9tluysl",
        "outputId": "8dd49bb8-8352-4945-b878-279d3c999a9f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! All values calculated correctly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here How to use nsys with colab"
      ],
      "metadata": {
        "id": "bU_yn_fIyGeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nsys profile --stats=true -o vector-add-report ./vectoradd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwkp5cnqyGFB",
        "outputId": "672627a6-6202-4e6c-aae0-3be17c42be80"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success! All values calculated correctly.\n",
            "Generating '/tmp/nsys-report-7ddf.qdstrm'\n",
            "[1/8] [========================100%] vector-add-report.nsys-rep\n",
            "[2/8] [========================100%] vector-add-report.sqlite\n",
            "[3/8] Executing 'nvtx_sum' stats report\n",
            "SKIPPED: /content/Nbody/vector-add-report.sqlite does not contain NV Tools Extension (NVTX) data.\n",
            "[4/8] Executing 'osrt_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)      Med (ns)    Min (ns)   Max (ns)    StdDev (ns)        Name     \n",
            " --------  ---------------  ---------  ------------  ------------  --------  -----------  ------------  --------------\n",
            "     92.9    1,241,706,931         72  17,245,929.6  10,077,421.5     3,936  100,152,052  25,788,117.1  poll          \n",
            "      5.0       66,921,602        541     123,699.8      12,566.0       490   18,726,539     998,002.8  ioctl         \n",
            "      1.7       22,930,105         24     955,421.0       8,181.5     3,124    9,813,825   2,610,883.3  mmap          \n",
            "      0.2        2,194,308         31      70,784.1      15,531.0    11,952    1,322,112     233,520.0  mmap64        \n",
            "      0.1        1,765,930         10     176,593.0      57,154.0    28,090      994,144     302,909.7  sem_timedwait \n",
            "      0.0          518,385         49      10,579.3      10,065.0     3,015       19,302       2,920.7  open64        \n",
            "      0.0          250,967         40       6,274.2       4,620.0     1,640       27,287       5,807.2  fopen         \n",
            "      0.0          122,443          2      61,221.5      61,221.5    57,433       65,010       5,357.7  pthread_create\n",
            "      0.0           98,819         11       8,983.5       8,265.0     4,015       17,557       3,545.0  munmap        \n",
            "      0.0           68,292         33       2,069.5       2,179.0     1,047        4,579         849.9  fclose        \n",
            "      0.0           54,801         11       4,981.9       5,310.0     1,458        6,632       1,695.8  write         \n",
            "      0.0           47,626          5       9,525.2       2,354.0       106       22,516      11,791.5  fread         \n",
            "      0.0           45,607          6       7,601.2       5,624.0     1,799       19,041       6,113.2  open          \n",
            "      0.0           43,480         58         749.7         594.5       221        8,244       1,027.6  fcntl         \n",
            "      0.0           40,636         17       2,390.4          45.0        44       39,816       9,644.4  fgets         \n",
            "      0.0           30,761         14       2,197.2       1,458.5       916        9,307       2,198.0  read          \n",
            "      0.0           26,636          2      13,318.0      13,318.0     9,675       16,961       5,152.0  socket        \n",
            "      0.0           14,606          1      14,606.0      14,606.0    14,606       14,606           0.0  connect       \n",
            "      0.0            9,802          1       9,802.0       9,802.0     9,802        9,802           0.0  pipe2         \n",
            "      0.0            3,166          8         395.8         372.0       310          564          91.8  dup           \n",
            "      0.0            1,990          1       1,990.0       1,990.0     1,990        1,990           0.0  bind          \n",
            "      0.0            1,341          1       1,341.0       1,341.0     1,341        1,341           0.0  listen        \n",
            "\n",
            "[5/8] Executing 'cuda_api_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)            Name         \n",
            " --------  ---------------  ---------  -------------  -------------  -----------  -----------  ------------  ----------------------\n",
            "     47.2      117,286,716          3   39,095,572.0       63,676.0       31,722  117,191,318  67,632,901.9  cudaMallocManaged     \n",
            "     43.4      107,810,843          1  107,810,843.0  107,810,843.0  107,810,843  107,810,843           0.0  cudaDeviceSynchronize \n",
            "      9.2       22,900,297          3    7,633,432.3    6,565,510.0    6,463,586    9,871,201   1,938,634.5  cudaFree              \n",
            "      0.2          407,445          1      407,445.0      407,445.0      407,445      407,445           0.0  cudaLaunchKernel      \n",
            "      0.0            1,848          1        1,848.0        1,848.0        1,848        1,848           0.0  cuModuleGetLoadingMode\n",
            "\n",
            "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Instances    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)                       Name                     \n",
            " --------  ---------------  ---------  -------------  -------------  -----------  -----------  -----------  ----------------------------------------------\n",
            "    100.0      107,794,969          1  107,794,969.0  107,794,969.0  107,794,969  107,794,969          0.0  addVectorsInto(float *, float *, float *, int)\n",
            "\n",
            "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)              Operation            \n",
            " --------  ---------------  -----  --------  --------  --------  --------  -----------  ---------------------------------\n",
            "     83.3       56,521,642  8,149   6,936.0   3,774.0     2,655    71,229      9,411.2  [CUDA Unified Memory memcpy HtoD]\n",
            "     16.7       11,347,860    768  14,775.9   6,207.5     1,982    79,551     22,201.7  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
            "\n",
            " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)              Operation            \n",
            " ----------  -----  --------  --------  --------  --------  -----------  ---------------------------------\n",
            "    402.653  8,149     0.049     0.008     0.004     0.782        0.115  [CUDA Unified Memory memcpy HtoD]\n",
            "    134.218    768     0.175     0.033     0.004     1.044        0.301  [CUDA Unified Memory memcpy DtoH]\n",
            "\n",
            "Generated:\n",
            "    /content/Nbody/vector-add-report.nsys-rep\n",
            "    /content/Nbody/vector-add-report.sqlite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp87YxwqsWFD"
      },
      "source": [
        "---\n",
        "# Final Exercise: Accelerate and Optimize an N-Body Simulator\n",
        "\n",
        "An [n-body](https://en.wikipedia.org/wiki/N-body_problem) simulator predicts the individual motions of a group of objects interacting with each other gravitationally. 01-nbody.cu contains a simple, though working, n-body simulator for bodies moving through 3 dimensional space.\n",
        "\n",
        "In its current CPU-only form, this application takes about 5 seconds to run on 4096 particles, and **20 minutes** to run on 65536 particles. Your task is to GPU accelerate the program, retaining the correctness of the simulation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPYT41S2sWFD"
      },
      "source": [
        "### Considerations to Guide Your Work\n",
        "\n",
        "Here are some things to consider before beginning your work:\n",
        "\n",
        "- Especially for your first refactors, the logic of the application, the `bodyForce` function in particular, can and should remain largely unchanged: focus on accelerating it as easily as possible.\n",
        "- The code base contains a for-loop inside `main` for integrating the interbody forces calculated by `bodyForce` into the positions of the bodies in the system. This integration both needs to occur after `bodyForce` runs, and, needs to complete before the next call to `bodyForce`. Keep this in mind when choosing how and where to parallelize.\n",
        "- Use a **profile driven** and iterative approach.\n",
        "- You are not required to add error handling to your code, but you might find it helpful, as you are responsible for your code working correctly.\n",
        "\n",
        "**Have Fun!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWmLxkzcsWFE"
      },
      "source": [
        "Use this cell to compile the nbody simulator. Although it is initially a CPU-only application, is does accurately simulate the positions of the particles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "scrolled": true,
        "id": "tcnd47mesWFE"
      },
      "outputs": [],
      "source": [
        "!nvcc -std=c++11 -o nbody 01-nbody.cu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFvPmcuasWFF"
      },
      "source": [
        "It is highly recommended you use the profiler to assist your work. Execute the following cell to generate a report file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcf2tIU-sWFF",
        "outputId": "8b699fab-1594-4ce8-d97f-53d31affaac1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.040 Billion Interactions / second\n",
            "Generating '/tmp/nsys-report-7fc1.qdstrm'\n",
            "[1/8] [========================100%] nbody-report.nsys-rep\n",
            "[2/8] [========================100%] nbody-report.sqlite\n",
            "[3/8] Executing 'nvtx_sum' stats report\n",
            "SKIPPED: /content/Nbody/nbody-report.sqlite does not contain NV Tools Extension (NVTX) data.\n",
            "[4/8] Executing 'osrt_sum' stats report\n",
            "\n",
            " Time (%)  Total Time (ns)  Num Calls  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)   Name  \n",
            " --------  ---------------  ---------  --------  --------  --------  --------  -----------  -------\n",
            "     97.7           42,704          2  21,352.0  21,352.0    20,590    22,114      1,077.6  fopen64\n",
            "      2.3            1,027         10     102.7      36.5        35       584        171.2  fflush \n",
            "\n",
            "[5/8] Executing 'cuda_api_sum' stats report\n",
            "SKIPPED: /content/Nbody/nbody-report.sqlite does not contain CUDA trace data.\n",
            "[6/8] Executing 'cuda_gpu_kern_sum' stats report\n",
            "SKIPPED: /content/Nbody/nbody-report.sqlite does not contain CUDA kernel data.\n",
            "[7/8] Executing 'cuda_gpu_mem_time_sum' stats report\n",
            "SKIPPED: /content/Nbody/nbody-report.sqlite does not contain GPU memory data.\n",
            "[8/8] Executing 'cuda_gpu_mem_size_sum' stats report\n",
            "SKIPPED: /content/Nbody/nbody-report.sqlite does not contain GPU memory data.\n",
            "Generated:\n",
            "    /content/Nbody/nbody-report.nsys-rep\n",
            "    /content/Nbody/nbody-report.sqlite\n"
          ]
        }
      ],
      "source": [
        "!nsys profile --stats=true --force-overwrite=true -o nbody-report ./nbody"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYpBRvH2sWFF"
      },
      "source": [
        "Here we import a function that will run your `nbody` simulator against a various number of particles, checking for performance and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZikBm-RgsWFG"
      },
      "outputs": [],
      "source": [
        "from assessment import run_assessment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sAIrVNNsWFG"
      },
      "source": [
        "Execute the following cell to run and assess `nbody`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "80Q9QOq4sWFH"
      },
      "outputs": [],
      "source": [
        "run_assessment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30o3xXsxsWFH"
      },
      "source": [
        "## Generate a Certificate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-PEBplRsWFH"
      },
      "source": [
        "If you passed the assessment, please return to the course page (shown below) and click the \"ASSESS TASK\" button, which will generate your certificate for the course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptfEL1X6sWFI"
      },
      "source": [
        "![run_assessment](./images/run_assessment.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpaUlWrYsWFI"
      },
      "source": [
        "## Advanced Content\n",
        "\n",
        "The following sections, for those of you with time and interest, introduce more intermediate techniques involving some manual device memory management, and using non-default streams to overlap kernel execution and memory copies.\n",
        "\n",
        "After learning about each of the techniques below, try to further optimize your nbody simulation using these techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NviPG3N3sWFI"
      },
      "source": [
        "---\n",
        "## Manual Device Memory Allocation and Copying\n",
        "\n",
        "While `cudaMallocManaged` and `cudaMemPrefetchAsync` are performant, and greatly simplify memory migration, sometimes it can be worth it to use more manual methods for memory allocation. This is particularly true when it is known that data will only be accessed on the device or host, and the cost of migrating data can be reclaimed in exchange for the fact that no automatic on-demand migration is needed.\n",
        "\n",
        "Additionally, using manual device memory management can allow for the use of non-default streams for overlapping data transfers with computational work. In this section you will learn some basic manual device memory allocation and copy techniques, before extending these techniques to overlap data copies with computational work.\n",
        "\n",
        "Here are some CUDA commands for manual device memory management:\n",
        "\n",
        "- `cudaMalloc` will allocate memory directly to the active GPU. This prevents all GPU page faults. In exchange, the pointer it returns is not available for access by host code.\n",
        "- `cudaMallocHost` will allocate memory directly to the CPU. It also \"pins\" the memory, or page locks it, which will allow for asynchronous copying of the memory to and from a GPU. Too much pinned memory can interfere with CPU performance, so use it only with intention. Pinned memory should be freed with `cudaFreeHost`.\n",
        "- `cudaMemcpy` can copy (not transfer) memory, either from host to device or from device to host."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcONWcHzsWFJ"
      },
      "source": [
        "### Manual Device Memory Management Example\n",
        "\n",
        "Here is a snippet of code that demonstrates the use of the above CUDA API calls.\n",
        "\n",
        "```cpp\n",
        "int *host_a, *device_a;        // Define host-specific and device-specific arrays.\n",
        "cudaMalloc(&device_a, size);   // `device_a` is immediately available on the GPU.\n",
        "cudaMallocHost(&host_a, size); // `host_a` is immediately available on CPU, and is page-locked, or pinned.\n",
        "\n",
        "initializeOnHost(host_a, N);   // No CPU page faulting since memory is already allocated on the host.\n",
        "\n",
        "// `cudaMemcpy` takes the destination, source, size, and a CUDA-provided variable for the direction of the copy.\n",
        "cudaMemcpy(device_a, host_a, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "kernel<<<blocks, threads, 0, someStream>>>(device_a, N);\n",
        "\n",
        "// `cudaMemcpy` can also copy data from device to host.\n",
        "cudaMemcpy(host_a, device_a, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "verifyOnHost(host_a, N);\n",
        "\n",
        "cudaFree(device_a);\n",
        "cudaFreeHost(host_a);          // Free pinned memory like this.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPy7iYuDsWFJ"
      },
      "source": [
        "### Exercise: Manually Allocate Host and Device Memory\n",
        "\n",
        "The most recent iteration of the vector addition application, [01-stream-init-solution](../edit/06-stream-init/solutions/01-stream-init-solution.cu), is using `cudaMallocManaged` to allocate managed memory first used on the device by the initialization kernels, then on the device by the vector add kernel, and then by the host, where the memory is automatically transferred, for verification. This is a sensible approach, but it is worth experimenting with some manual device memory allocation and copying to observe its impact on the application's performance.\n",
        "\n",
        "Refactor the [01-stream-init-solution](../edit/06-stream-init/solutions/01-stream-init-solution.cu) application to **not** use `cudaMallocManaged`. In order to do this you will need to do the following:\n",
        "\n",
        "- Replace calls to `cudaMallocManaged` with `cudaMalloc`.\n",
        "- Create an additional vector that will be used for verification on the host. This is required since the memory allocated with `cudaMalloc` is not available to the host. Allocate this host vector with `cudaMallocHost`.\n",
        "- After the `addVectorsInto` kernel completes, use `cudaMemcpy` to copy the vector with the addition results, into the host vector you created with `cudaMallocHost`.\n",
        "- Use `cudaFreeHost` to free the memory allocated with `cudaMallocHost`.\n",
        "\n",
        "Refer to [the solution](../edit/07-manual-malloc/solutions/01-manual-malloc-solution.cu) if you get stuck."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPwSept2sWFK"
      },
      "outputs": [],
      "source": [
        "!nvcc -o vector-add-manual-alloc 06-stream-init/solutions/01-stream-init-solution.cu -run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvSWymuUsWFL"
      },
      "source": [
        "After completing the refactor, open a report in Nsight Systems, and use the timeline to do the following:\n",
        "\n",
        "- Notice that there is no longer a *Unified Memory* section of the timeline.\n",
        "- Comparing this timeline to that of the previous refactor, compare the run times of `cudaMalloc` in the current application vs. `cudaMallocManaged` in the previous.\n",
        "- Notice how in the current application, work on the initialization kernels does not start until a later time than it did in the previous iteration. Examination of the timeline will show the difference is the time taken by `cudaMallocHost`. This clearly points out the difference between memory transfers, and memory copies. When copying memory, as you are doing presently, the data will exist in 2 different places in the system. In the current case, the allocation of the 4th host-only vector incurs a small cost in performance, compared to only allocating 3 vectors in the previous iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-V7rJnjsWFM"
      },
      "source": [
        "---\n",
        "## Using Streams to Overlap Data Transfers and Code Execution\n",
        "\n",
        "The following slides present upcoming material visually, at a high level. Click through the slides before moving on to more detailed coverage of their topics in following sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywXpy16-sWFM"
      },
      "outputs": [],
      "source": [
        "%%HTML\n",
        "\n",
        "<div align=\"center\"><iframe src=\"https://view.officeapps.live.com/op/view.aspx?src=https://developer.download.nvidia.com/training/courses/C-AC-01-V1/embedded/task3/NVVP-Streams-3.pptx\" width=\"800px\" height=\"500px\" frameborder=\"0\"></iframe></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S4zsekmsWFN"
      },
      "source": [
        "In addition to `cudaMemcpy` is `cudaMemcpyAsync` which can asynchronously copy memory either from host to device or from device to host as long as the host memory is pinned, which can be done by allocating it with `cudaMallocHost`.\n",
        "\n",
        "Similar to kernel execution, `cudaMemcpyAsync` is only asynchronous by default with respect to the host. It executes, by default, in the default stream and therefore is a blocking operation with regard to other CUDA operations occurring on the GPU. The `cudaMemcpyAsync` function, however, takes as an optional 5th argument, a non-default stream. By passing it a non-default stream, the memory transfer can be concurrent to other CUDA operations occurring in other non-default streams.\n",
        "\n",
        "A common and useful pattern is to use a combination of pinned host memory, asynchronous memory copies in non-default streams, and kernel executions in non-default streams, to overlap memory transfers with kernel execution.\n",
        "\n",
        "In the following example, rather than wait for the entire memory copy to complete before beginning work on the kernel, segments of the required data are copied and worked on, with each copy/work segment running in its own non-default stream. Using this technique, work on parts of the data can begin while memory transfers for later segments occur concurrently. Extra care must be taken when using this technique to calculate segment-specific values for the number of operations, and the offset location inside arrays, as shown here:\n",
        "\n",
        "```cpp\n",
        "int N = 2<<24;\n",
        "int size = N * sizeof(int);\n",
        "\n",
        "int *host_array;\n",
        "int *device_array;\n",
        "\n",
        "cudaMallocHost(&host_array, size);               // Pinned host memory allocation.\n",
        "cudaMalloc(&device_array, size);                 // Allocation directly on the active GPU device.\n",
        "\n",
        "initializeData(host_array, N);                   // Assume this application needs to initialize on the host.\n",
        "\n",
        "const int numberOfSegments = 4;                  // This example demonstrates slicing the work into 4 segments.\n",
        "int segmentN = N / numberOfSegments;             // A value for a segment's worth of `N` is needed.\n",
        "size_t segmentSize = size / numberOfSegments;    // A value for a segment's worth of `size` is needed.\n",
        "\n",
        "// For each of the 4 segments...\n",
        "for (int i = 0; i < numberOfSegments; ++i)\n",
        "{\n",
        "  // Calculate the index where this particular segment should operate within the larger arrays.\n",
        "  segmentOffset = i * segmentN;\n",
        "\n",
        "  // Create a stream for this segment's worth of copy and work.\n",
        "  cudaStream_t stream;\n",
        "  cudaStreamCreate(&stream);\n",
        "  \n",
        "  // Asynchronously copy segment's worth of pinned host memory to device over non-default stream.\n",
        "  cudaMemcpyAsync(&device_array[segmentOffset],  // Take care to access correct location in array.\n",
        "                  &host_array[segmentOffset],    // Take care to access correct location in array.\n",
        "                  segmentSize,                   // Only copy a segment's worth of memory.\n",
        "                  cudaMemcpyHostToDevice,\n",
        "                  stream);                       // Provide optional argument for non-default stream.\n",
        "                  \n",
        "  // Execute segment's worth of work over same non-default stream as memory copy.\n",
        "  kernel<<<number_of_blocks, threads_per_block, 0, stream>>>(&device_array[segmentOffset], segmentN);\n",
        "  \n",
        "  // `cudaStreamDestroy` will return immediately (is non-blocking), but will not actually destroy stream until\n",
        "  // all stream operations are complete.\n",
        "  cudaStreamDestroy(stream);\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y0-NTMdsWFN"
      },
      "source": [
        "### Exercise: Overlap Kernel Execution and Memory Copy Back to Host\n",
        "\n",
        "The most recent iteration of the vector addition application, [01-manual-malloc-solution.cu](../edit/07-manual-malloc/solutions/01-manual-malloc-solution.cu), is currently performing all of its vector addition work on the GPU before copying the memory back to the host for verification.\n",
        "\n",
        "Refactor [01-manual-malloc-solution.cu](../edit/07-manual-malloc/solutions/01-manual-malloc-solution.cu) to perform the vector addition in 4 segments, in non-default streams, so that asynchronous memory copies can begin before waiting for all vector addition work to complete. Refer to [the solution](../edit/08-overlap-xfer/solutions/01-overlap-xfer-solution.cu) if you get stuck."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ayga3WksWFO"
      },
      "outputs": [],
      "source": [
        "!nvcc -o vector-add-manual-alloc 07-manual-malloc/solutions/01-manual-malloc-solution.cu -run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvwXfylMsWFP"
      },
      "source": [
        "After completing the refactor, open a report in Nsight Systems, and use the timeline to do the following:\n",
        "\n",
        "- Note when the device to host memory transfers begin, is it before or after all kernel work has completed?\n",
        "- Notice that the 4 memory copy segments themselves do not overlap. Even in separate non-default streams, only one memory transfer in a given direction (DtoH here) at a time can occur simultaneously. The performance gains here are in the ability to start the transfers earlier than otherwise, and it is not hard to imagine in an application where a less trivial amount of work was being done compared to a simple addition operation, that the memory copies would not only start earlier, but also overlap with kernel execution."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "R3apYEbTsq8Y",
        "UYW2yGN5vAL1"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}